{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6f1da240-ec9b-441f-9d47-44c6dc85d540",
            "metadata": {},
            "source": [
                "## Part 4: Human-in-the-loop\n",
                "\n",
                "Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\n",
                "\n",
                "LangGraph supports `human-in-the-loop` workflows in a number of ways. In this section, we will use LangGraph's `interrupt_before` functionality to always break the tool node.\n",
                "\n",
                "First, start from our existing code. The following is copied from Part 3."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "5a81608a-373a-4339-b1c6-65b73a92b983",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<langgraph.graph.state.StateGraph at 0x7ff63dafb9d0>"
                        ]
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from typing import Annotated\n",
                "\n",
                "from langchain_anthropic import ChatAnthropic\n",
                "from langchain_community.tools.tavily_search import TavilySearchResults\n",
                "from typing_extensions import TypedDict\n",
                "\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langgraph.graph import StateGraph, START\n",
                "from langgraph.graph.message import add_messages\n",
                "from langgraph.prebuilt import ToolNode, tools_condition\n",
                "\n",
                "memory = MemorySaver()\n",
                "\n",
                "\n",
                "class State(TypedDict):\n",
                "    messages: Annotated[list, add_messages]\n",
                "\n",
                "\n",
                "graph_builder = StateGraph(State)\n",
                "\n",
                "\n",
                "tool = TavilySearchResults(max_results=2)\n",
                "tools = [tool]\n",
                "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
                "llm_with_tools = llm.bind_tools(tools)\n",
                "\n",
                "\n",
                "def chatbot(state: State):\n",
                "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
                "\n",
                "\n",
                "graph_builder.add_node(\"chatbot\", chatbot)\n",
                "\n",
                "tool_node = ToolNode(tools=[tool])\n",
                "graph_builder.add_node(\"tools\", tool_node)\n",
                "\n",
                "graph_builder.add_conditional_edges(\n",
                "    \"chatbot\",\n",
                "    tools_condition,\n",
                ")\n",
                "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
                "graph_builder.add_edge(START, \"chatbot\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "813505b2-18c1-46e9-b891-20a34232808b",
            "metadata": {},
            "source": [
                "Now, compile the graph, specifying to `interrupt_before` the `tools` node."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "b0883e32-1a39-4ce9-ae32-bbd66708fd84",
            "metadata": {},
            "outputs": [],
            "source": [
                "graph = graph_builder.compile(\n",
                "    checkpointer=memory,\n",
                "    # This is new!\n",
                "    interrupt_before=[\"tools\"],\n",
                "    # Note: can also interrupt __after__ tools, if desired.\n",
                "    # interrupt_after=[\"tools\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "9f318020-ab7e-415b-a5e2-eddec6d9f3a6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "I'm learning LangGraph. Could you do some research on it for me?\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01FyRG3beSfagX6ceQ57Awjb', 'input': {'query': 'LangGraph: what is it, how is it used, and its features'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
                        "Tool Calls:\n",
                        "  tavily_search_results_json (toolu_01FyRG3beSfagX6ceQ57Awjb)\n",
                        " Call ID: toolu_01FyRG3beSfagX6ceQ57Awjb\n",
                        "  Args:\n",
                        "    query: LangGraph: what is it, how is it used, and its features\n"
                    ]
                }
            ],
            "source": [
                "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
                "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "# The config is the **second positional argument** to stream() or invoke()!\n",
                "events = graph.stream(\n",
                "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
                ")\n",
                "for event in events:\n",
                "    if \"messages\" in event:\n",
                "        event[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39405637-13b1-40b1-a51e-6d60bf675ff1",
            "metadata": {},
            "source": [
                "Let's inspect the graph state to confirm it worked."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "9bb7af46-9b4f-4bb1-b8b9-e9ddf7dbc82c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "('tools',)"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "snapshot = graph.get_state(config)\n",
                "snapshot.next"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89326046-2b11-4812-8b6d-8780306ec275",
            "metadata": {},
            "source": [
                "**Notice** that unlike last time, the \"next\" node is set to **'tools'**. We've interrupted here! Let's check the tool invocation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "id": "3facda0a-e6ad-4b28-b627-753ad8c90c15",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'name': 'tavily_search_results_json',\n",
                            "  'args': {'query': 'LangGraph: what is it, how is it used, and its features'},\n",
                            "  'id': 'toolu_01FyRG3beSfagX6ceQ57Awjb',\n",
                            "  'type': 'tool_call'}]"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "existing_message = snapshot.values[\"messages\"][-1]\n",
                "existing_message.tool_calls"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a55a4c70-7226-4be0-8562-391f72bc1f2b",
            "metadata": {},
            "source": [
                "This query seems reasonable. Nothing to filter here. The simplest thing the human can do is just let the graph continue executing. Let's do that below.\n",
                "\n",
                "Next, continue the graph! Passing in `None` will just let the graph continue where it left off, without adding anything new to the state."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "effb95d9-b7d5-40c5-9253-253d193b23b2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01FyRG3beSfagX6ceQ57Awjb', 'input': {'query': 'LangGraph: what is it, how is it used, and its features'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
                        "Tool Calls:\n",
                        "  tavily_search_results_json (toolu_01FyRG3beSfagX6ceQ57Awjb)\n",
                        " Call ID: toolu_01FyRG3beSfagX6ceQ57Awjb\n",
                        "  Args:\n",
                        "    query: LangGraph: what is it, how is it used, and its features\n",
                        "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
                        "Name: tavily_search_results_json\n",
                        "\n",
                        "[{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"In LangGraph, each node represents an LLM agent, and the edges are the communication channels between these agents. This structure allows for clear and manageable workflows, where each agent performs specific tasks and passes information to other agents as needed. State management. One of LangGraph's standout features is its automatic state\"}, {\"url\": \"https://towardsdatascience.com/from-basics-to-advanced-exploring-langgraph-e8c1cf4db787\", \"content\": \"LangGraph, however, takes a different approach. While CrewAI is a high-level framework with many predefined features and ready-to-use components, LangGraph operates at a lower level, offering extensive customization and control. With that introduction, let's dive into the fundamental concepts of LangGraph. LangGraph basics\"}]\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "Great! I've found some information about LangGraph for you. Let me summarize the key points:\n",
                        "\n",
                        "1. What is LangGraph?\n",
                        "LangGraph is a framework for building applications with language models (LLMs). It provides a way to structure and manage complex workflows involving multiple AI agents.\n",
                        "\n",
                        "2. How is it used?\n",
                        "LangGraph is used to create graph-like structures where:\n",
                        "- Each node in the graph represents an LLM agent\n",
                        "- The edges between nodes represent communication channels between agents\n",
                        "\n",
                        "This structure allows developers to create clear and manageable workflows where each agent performs specific tasks and passes information to other agents as needed.\n",
                        "\n",
                        "3. Key Features:\n",
                        "a) State Management: One of LangGraph's standout features is its automatic state management. This likely helps in maintaining the context and progress of complex multi-agent interactions.\n",
                        "\n",
                        "b) Customization and Control: Unlike some other frameworks (such as CrewAI), LangGraph operates at a lower level, offering extensive customization and control. This makes it suitable for developers who need fine-grained control over their LLM-based applications.\n",
                        "\n",
                        "c) Workflow Management: LangGraph allows for the creation of clear and structured workflows, which can be especially useful in complex AI applications involving multiple steps or agents.\n",
                        "\n",
                        "4. Comparison to Other Frameworks:\n",
                        "The sources mention that LangGraph differs from frameworks like CrewAI. While CrewAI is described as a high-level framework with many predefined features and ready-to-use components, LangGraph offers more low-level control and customization options.\n",
                        "\n",
                        "5. Use Cases:\n",
                        "While not explicitly mentioned in the search results, LangGraph would be particularly useful for:\n",
                        "- Building complex AI systems that require multiple agents to work together\n",
                        "- Creating applications that need fine-grained control over LLM interactions\n",
                        "- Developing workflows where different AI agents need to perform specific tasks and communicate results\n",
                        "\n",
                        "LangGraph seems to be a powerful tool for developers looking to create sophisticated, multi-agent AI systems with a high degree of control and customization. It's particularly suited for those who need to manage complex workflows and state in their LLM-based applications.\n",
                        "\n",
                        "Is there any specific aspect of LangGraph you'd like to know more about? I'd be happy to do further research on particular features or use cases if you're interested.\n"
                    ]
                }
            ],
            "source": [
                "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
                "events = graph.stream(None, config, stream_mode=\"values\")\n",
                "for event in events:\n",
                "    if \"messages\" in event:\n",
                "        event[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "21e78a97-474f-4709-b51d-9d5e8323e14c",
            "metadata": {},
            "source": [
                "Review this call's [LangSmith trace](https://smith.langchain.com/public/4d7f8757-9d3b-43b9-88b6-aeab0595bc4c/r) to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that your chatbot can continue where it left off.\n",
                "\n",
                "**Congrats!** You've used an `interrupt` to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a **checkpointer**, the graph can be paused **indefinitely** and resumed at any time as if nothing had happened.\n",
                "\n",
                "Next, we'll explore how to further customize the bot's behavior using custom state updates.\n",
                "\n",
                "Below is a copy of the code you used in this section. The only difference between this and the previous parts is the addition of the `interrupt_before` argument.\n",
                "\n",
                "<details>\n",
                "<summary>Full Code</summary>\n",
                "    <pre>\n",
                "\n",
                "```python\n",
                "from typing import Annotated\n",
                "\n",
                "from langchain_anthropic import ChatAnthropic\n",
                "from langchain_community.tools.tavily_search import TavilySearchResults\n",
                "from langchain_core.messages import BaseMessage\n",
                "from typing_extensions import TypedDict\n",
                "\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langgraph.graph import StateGraph\n",
                "from langgraph.graph.message import add_messages\n",
                "from langgraph.prebuilt import ToolNode, tools_condition\n",
                "\n",
                "\n",
                "class State(TypedDict):\n",
                "    messages: Annotated[list, add_messages]\n",
                "\n",
                "\n",
                "graph_builder = StateGraph(State)\n",
                "\n",
                "\n",
                "tool = TavilySearchResults(max_results=2)\n",
                "tools = [tool]\n",
                "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
                "llm_with_tools = llm.bind_tools(tools)\n",
                "\n",
                "\n",
                "def chatbot(state: State):\n",
                "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
                "\n",
                "\n",
                "graph_builder.add_node(\"chatbot\", chatbot)\n",
                "\n",
                "tool_node = ToolNode(tools=[tool])\n",
                "graph_builder.add_node(\"tools\", tool_node)\n",
                "\n",
                "graph_builder.add_conditional_edges(\n",
                "    \"chatbot\",\n",
                "    tools_condition,\n",
                ")\n",
                "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
                "graph_builder.set_entry_point(\"chatbot\")\n",
                "\n",
                "memory = MemorySaver()\n",
                "graph = graph_builder.compile(\n",
                "    checkpointer=memory,\n",
                "    # This is new!\n",
                "    interrupt_before=[\"tools\"],\n",
                "    # Note: can also interrupt __after__ actions, if desired.\n",
                "    # interrupt_after=[\"tools\"]\n",
                ")\n",
                "```\n",
                "</pre>\n",
                "</details>"
            ]
        }
    ]
}
